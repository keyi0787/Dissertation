---
title: "Untitled"
output: html_document
date: "2024-06-23"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

# try to extract the shp for Westminster
## packages
```{r}
library(sf)
library(dplyr)
```
## read in and extract
```{r}
# Read the shapefile
london_shp <- st_read("data/statistical-gis-boundaries-london/ESRI/London_Borough_Excluding_MHW.shp")

# Filter for Westminster
westminster_shp <- london_shp %>% filter(NAME == "Westminster")
```
## export
```{r}
# Export the new shapefile
st_write(westminster_shp, "data/westminster_shapefile.shp")
```
## cut london_shp into half-half
```{r}
# Check the number of features
n_features <- nrow(london_shp)

# Generate random indices to split the data evenly
set.seed(123) # Set seed for reproducibility
indices <- sample(seq_len(n_features), size = n_features / 2)

# Split the shapefile into two parts
london_shp_part1 <- london_shp[indices, ]
london_shp_part2 <- london_shp[-indices, ]

# Optionally, save the split shapefiles
st_write(london_shp_part1, "data/london_shp/part1/london_shp_part1.shp")
st_write(london_shp_part2, "data/london_shp/part2/london_shp_part2.shp")
```







# Draft data processing

## packages
```{r}
library(tidyverse)
library(sf)
library(tmap)
library(janitor)
library(spatstat)
library(dbscan)
library(ggplot2)
library(raster)
library(fpc)
library(r5r)
library(elevatr)
```
## data loading
```{r}
# replace the NA values when i read the data in
poi <- read_csv("data/cultural_poi.csv", na=c(" "))

Westminster <- st_read("data/westminster_shp/westminster_shapefile.shp")
```
Here I want to check the data type to see if there are some numeric data become characteristic because of NA
```{r}
# check the csv
Datatypelist <- poi %>% 
  summarise_all(class) %>%
  pivot_longer(everything(), 
               names_to="All_variables", 
               values_to="Variable_class")

Datatypelist
```
# check the crs of westminster
```{r}
# check the shp
tm_shape(Westminster) +
  tm_polygons(col = NA, alpha = 0.5)

# Check the CRS of the shapefile
crs_info <- st_crs(Westminster)
print(crs_info)
#need to transform to 27700
Westminster <- st_transform(Westminster,27700)
```

## Data wrangling
### transform my csv data into spatial data using sf
```{r}
points <- poi%>%
  #to exclude those data points which are out of range 
  st_as_sf(., coords = c("feature_easting", "feature_northing"), 
                   crs = 27700)
# Verify the CRS of points
print(st_crs(points))
```

```{r}
tmap_mode("plot")

tm_shape(Westminster) +
  tm_polygons(col = NA, alpha = 0.5) +
  tm_shape(points) +
  tm_dots(col = "blue")
```
# NO CLASSIFICATION!
### ppp object
Create a observation window to explore the point pattern along with a ppp object.
```{r}
window <- as.owin(Westminster)
plot(window)

#create a sp object
points_sp<- points %>%
  as(., 'Spatial')
#create a ppp object
points_sp.ppp <- ppp(x=points_sp@coords[,1],
                     y=points_sp@coords[,2],
                     window=window)
points_sp.ppp %>%
  plot(.,pch=16,cex=0.5, 
       main="Westminster POI")
```

### Ripley's K
This method can compare the observed distribution of points with the Poisson random model for a whole range of different distance radii. Compared with Quadrat analysis, this method can get around the limitation of being affceted by the change of units.
```{r}
K <- points_sp.ppp %>%
  Kest(., correction="border") %>%
  plot()

Kval <- as.data.frame(Kest(points_sp.ppp, correction = "Ripley"))
```
The red line is what we expect. The result seems to show a large difference between the pattern of point data and what we expected. Meanwhile, it's clear that the black line becomes gradually larger than the red line. Thus, there may be some spatial clustering for the 2020 London Eviction data.
### DBSCAN
Now we get the basic presentation of Ripley's K, but we still have no idea where the clustering happens. Therefore, we run the DBSCAN to further investigate the problem.
To use the DBSCAN, we need to detremine the values for eps and MinPts.
```{r}
# used to find suitable eps value based on the knee in plot
# k is no of nearest neighbours used, use min points
#first extract the points from the spatial points data frame
points_todf <- points_sp %>%
  coordinates(.)%>%
  as.data.frame()

points_todf%>%
  dbscan::kNNdistplot(.,k=4)
```
determine the eps and minPts
```{r}
#now run the dbscan analysis
points_todf_DBSCAN <- points_todf %>%
  fpc::dbscan(.,eps = 200, MinPts = 4)

points_todf%>%
  dbscan::kNNdistplot(.,k=4)

#now quickly plot the results
plot(points_todf_DBSCAN, points_todf, main = "DBSCAN Output", frame = F)
plot(Westminster$geometry, add=T)
```
#### to find a suitable eps value
```{r}
# used to find suitable eps value based on the knee in plot
# k is no of nearest neighbours used, use min points
points_todf%>%
  dbscan::kNNdistplot(.,k=4)
```
Add the clustering information into the original dataframe
```{r}
points_todf<- points_todf %>%
  mutate(dbcluster=points_todf_DBSCAN$cluster) 
```
convert out original data frame into a sf object again (to include geometry elements)
```{r}
tosf <- points_todf%>%
  st_as_sf(., coords = c("coords.x1", "coords.x2"), 
                   crs = 27700)%>%
  filter(dbcluster>0)
```
Map the data
```{r}
ggplot(data = Westminster) +
  # add the geometry of the community areas
  geom_sf() +
  # add the geometry of the points - i have had to set the data here to add the layer
  geom_sf(data = tosf, size = 0.4, colour=tosf$dbcluster, fill=tosf$dbcluster)
```
#### create some convex hull polygons to wrap around the points in our clusters.
```{r}
chulls <- points_todf %>%
  group_by(dbcluster) %>%
  dplyr::mutate(hull = 1:n(),
  hull = factor(hull, chull(coords.x1, coords.x2)))%>%
  arrange(hull)

#chulls2 <- ddply(BluePlaquesSubPoints, .(dbcluster), 
              #  function(df) df[chull(df$coords.x1, df$coords.x2), ])
```
```{r}
chulls <- chulls %>%
  filter(dbcluster >=1)

dbplot <- ggplot(data=points_todf, 
                 aes(coords.x1,coords.x2, colour=dbcluster, fill=dbcluster)) 
#add the points in
dbplot <- dbplot + geom_point()
#now the convex hulls
dbplot <- dbplot + geom_polygon(data = chulls, 
                                aes(coords.x1,coords.x2, group=dbcluster), 
                                alpha = 0.5) 
#now plot, setting the coordinates to scale correctly and as a black and white plot 
#(just for the hell of it)...
dbplot + theme_bw() + coord_equal()
```
#### add a basemap
```{r}
library(OpenStreetMap)

###add a basemap
##First get the bbox in lat long for Harrow
WestminsterWGSbb <- Westminster %>%
  st_bbox()

# Define the bounding box in BNG coordinates
westminster_bbox <- st_bbox(c(xmin = 523843.7, ymin = 177847.3, xmax = 531169.1, ymax = 183893.8), crs = st_crs(27700))
# Convert the BNG bbox to WGS 84
westminster_bbox <- st_transform(st_as_sfc(westminster_bbox), crs = 4326)
westminster_bbox_coords <- st_bbox(westminster_bbox)
# Extract the bounding box coordinates in WGS 84
top_left <- c(westminster_bbox_coords$ymax, westminster_bbox_coords$xmin)
bottom_right <- c(westminster_bbox_coords$ymin, westminster_bbox_coords$xmax)

# Fetch the basemap using the WGS 84 coordinates
basemap <- OpenStreetMap::openmap(top_left, bottom_right, zoom = NULL, type = "osm")
# convert the basemap to British National Grid
basemap_bng <- openproj(basemap, projection="+init=epsg:27700")

#autoplot(basemap_bng) sometimes works
autoplot.OpenStreetMap(basemap_bng)+ 
  geom_point(data=points_todf, 
             aes(coords.x1,coords.x2, 
                 colour=dbcluster, 
                 fill=dbcluster)) + 
  geom_polygon(data = chulls, 
               aes(coords.x1,coords.x2, 
                   group=dbcluster), 
               alpha = 0.5)  
```
# Seperate Section!
```{r}
# Extract unique values from the specified column
sic_sections <- unique(points$SIC_Section)

# Print the unique values
print(sic_sections)
```
## IC
```{r}
seperate_group_IC <- points %>%
  filter(SIC_Section == "Information and Communication")
```
### ppp object
Create a observation window to explore the point pattern along with a ppp object.
```{r}
window <- as.owin(Westminster)
plot(window)

#create a sp object
group_sp_IC<- seperate_group_IC %>%
  as(., 'Spatial')
#create a ppp object
group_sp_IC.ppp <- ppp(x=group_sp_IC@coords[,1],
                     y=group_sp_IC@coords[,2],
                     window=window)
group_sp_IC.ppp %>%
  plot(.,pch=16,cex=0.5, 
       main="Westminster Information and Communication POI")
```
### Ripley's K
```{r}
K <- group_sp_IC.ppp %>%
  Kest(., correction="border") %>%
  plot(., main = "Ripley's K for Information and Communication")

Kval <- as.data.frame(Kest(group_sp_IC.ppp, correction = "Ripley"))
```
Where the value of K falls above the line, the data appear to be clustered at that distance. Where the value of K is below the line, the data are dispersed.
### DBSCAN
```{r}
# used to find suitable eps value based on the knee in plot
# k is no of nearest neighbours used, use min points
#first extract the points from the spatial points data frame
group_todf_IC <- group_sp_IC %>%
  coordinates(.)%>%
  as.data.frame()

group_todf_IC%>%
  dbscan::kNNdistplot(.,k=4)
```
```{r}
eps = 500
Minpts = 4
#now run the dbscan analysis
group_todf_DBSCAN_IC <- group_todf_IC %>%
  fpc::dbscan(.,eps = eps, MinPts = Minpts)

#now quickly plot the results
plot(group_todf_DBSCAN_IC, group_todf_IC, main = "DBSCAN Information and Communication Output", frame = F)
plot(Westminster$geometry, add=T)
```
### Add the clustering information into the original dataframe
```{r}
group_todf_dbinfo_IC <- group_todf_IC %>%
  mutate(dbcluster=group_todf_DBSCAN_IC$cluster) 
```
### export a csv file with dbinfo
```{r}
# Convert the data frame to an sf object
tosf_IC <- group_todf_dbinfo_IC %>%
  st_as_sf(., coords = c("coords.x1", "coords.x2"), 
              crs = 27700)%>%
  filter(dbcluster>0)

# Export the sf object as a shapefile
st_write(tosf_IC, "data/clusters/IC/IC.shp")
```
```{r}
tmap_mode("plot")

tm_shape(Westminster) +
  tm_polygons(col = NA, alpha = 0.5) +
  tm_shape(tosf) +
  tm_dots(col = "blue")
```
## Professional, Scientific and Technical Activities
```{r}
seperate_group_PST <- points %>%
  filter(SIC_Section == "Professional, Scientific and Technical Activities")
```
### ppp object
Create a observation window to explore the point pattern along with a ppp object.
```{r}
window <- as.owin(Westminster)
plot(window)

#create a sp object
group_sp_PST<- seperate_group_PST %>%
  as(., 'Spatial')
#create a ppp object
group_sp_PST.ppp <- ppp(x=group_sp_PST@coords[,1],
                     y=group_sp_PST@coords[,2],
                     window=window)
group_sp_PST.ppp %>%
  plot(.,pch=16,cex=0.5, 
       main="Westminster Professional, Scientific and Technical Activities POI")
```
### Ripley's K
```{r}
K <- group_sp_PST.ppp %>%
  Kest(., correction="border") %>%
  plot(., main = "Ripley's K for Professional, Scientific and Technical Activities")

Kval <- as.data.frame(Kest(group_sp_PST.ppp, correction = "Ripley"))
```
Where the value of K falls above the line, the data appear to be clustered at that distance. Where the value of K is below the line, the data are dispersed.
### DBSCAN
```{r}
# used to find suitable eps value based on the knee in plot
# k is no of nearest neighbours used, use min points
#first extract the points from the spatial points data frame
group_todf_PST <- group_sp_PST %>%
  coordinates(.)%>%
  as.data.frame()

group_todf_PST%>%
  dbscan::kNNdistplot(.,k=4)
```
```{r}
eps = 450
Minpts = 4
#now run the dbscan analysis
group_todf_DBSCAN_PST <- group_todf_PST %>%
  fpc::dbscan(.,eps = eps, MinPts = Minpts)

#now quickly plot the results
plot(group_todf_DBSCAN_PST, group_todf_PST, main = "DBSCAN Professional, Scientific and Technical Activities Output", frame = F)
plot(Westminster$geometry, add=T)
```
### Add the clustering information into the original dataframe
```{r}
group_todf_dbinfo_PST <- group_todf_PST %>%
  mutate(dbcluster=group_todf_DBSCAN_PST$cluster) 
```
### export a csv file with dbinfo
```{r}
# Convert the data frame to an sf object
tosf_PST <- group_todf_dbinfo_PST %>%
  st_as_sf(., coords = c("coords.x1", "coords.x2"), 
              crs = 27700)%>%
  filter(dbcluster>0)

# Export the sf object as a shapefile
st_write(tosf_PST, "data/clusters/PST/PST.shp")
```
## Arts, Entertainment and Recreation
```{r}
seperate_group_AER <- points %>%
  filter(SIC_Section == "Arts, Entertainment and Recreation")
```
### ppp object
Create a observation window to explore the point pattern along with a ppp object.
```{r}
window <- as.owin(Westminster)
plot(window)

#create a sp object
group_sp_AER<- seperate_group_AER %>%
  as(., 'Spatial')
#create a ppp object
group_sp_AER.ppp <- ppp(x=group_sp_AER@coords[,1],
                     y=group_sp_AER@coords[,2],
                     window=window)
group_sp_AER.ppp %>%
  plot(.,pch=16,cex=0.5, 
       main="Westminster Arts, Entertainment and Recreation POI")
```
### Ripley's K
```{r}
K <- group_sp_AER.ppp %>%
  Kest(., correction="border") %>%
  plot(., main = "Ripley's K for Arts, Entertainment and Recreation")

Kval <- as.data.frame(Kest(group_sp_AER.ppp, correction = "Ripley"))
```
Where the value of K falls above the line, the data appear to be clustered at that distance. Where the value of K is below the line, the data are dispersed.
### DBSCAN
```{r}
# used to find suitable eps value based on the knee in plot
# k is no of nearest neighbours used, use min points
#first extract the points from the spatial points data frame
group_todf_AER <- group_sp_AER %>%
  coordinates(.)%>%
  as.data.frame()

group_todf_AER%>%
  dbscan::kNNdistplot(.,k=4)
```
```{r}
eps = 750
Minpts = 4
#now run the dbscan analysis
group_todf_DBSCAN_AER <- group_todf_AER %>%
  fpc::dbscan(.,eps = eps, MinPts = Minpts)

#now quickly plot the results
plot(group_todf_DBSCAN_AER, group_todf_AER, main = "DBSCAN Arts, Entertainment and Recreation Output", frame = F)
plot(Westminster$geometry, add=T)
```
### Add the clustering information into the original dataframe
```{r}
group_todf_dbinfo_AER <- group_todf_AER %>%
  mutate(dbcluster=group_todf_DBSCAN_AER$cluster) 
```
### export a csv file with dbinfo
```{r}
# Convert the data frame to an sf object
tosf_AER <- group_todf_dbinfo_AER %>%
  st_as_sf(., coords = c("coords.x1", "coords.x2"), 
              crs = 27700)%>%
  filter(dbcluster>0)

# Export the sf object as a shapefile
st_write(tosf_AER, "data/clusters/AER/AER.shp")
```
# Urban Accessibility
## get pbf from OSM > download the pbf file from bbbike website
## get gtfs.zip from tidytransit package
```{r eval=FALSE}
library(tidytransit)

# Define the URL for the GTFS data (this is an example, you should replace it with the actual URL)
gtfs_url <- "http://www.londontransit.ca/gtfsfeed/google_transit.zip"

# Download the GTFS data
gtfs_zip <- tempfile(fileext = ".zip")
download.file(gtfs_url, gtfs_zip, mode = "wb")
```
## get tiff file of london topography
```{r}
# Reproject the shapefile to WGS 84 if necessary
if (st_crs(london_shp) != st_crs(4326)) {
  london_shp <- st_transform(london_shp, crs = 4326)
}

# Fetch the elevation data
elevation_raster <- get_elev_raster(locations = london_shp, z = 10, clip = "bbox")

# Save the raster to a file
output_file <- "data/r5/london_dem.tif"
writeRaster(elevation_raster, filename = output_file, format = "GTiff", overwrite = TRUE)
```

## travel matrix
```{r}
r5_path <- "data/r5-v7.2-all.jar"
data_path <- "data/r5" 

# Initialize R5 core with increased verbosity for debugging
r5r_core <- setup_r5(data_path = data_path, verbose = TRUE)
```

```{r}
hexagon <- read_csv("data/hexagons.csv", na=c(" "))
origins_df <- hexagon%>%
  #to exclude those data points which are out of range 
  st_as_sf(., coords = c("longitude", "latitude"), 
                   crs = 4326)

destinations_df <- st_transform(points, 4326)
```

```{r}
# Calculate travel time matrix
ttm <- travel_time_matrix(
  r5r_core = r5r_core,
  origins = origins_df,
  destinations = destinations_df,
  mode = "TRANSIT",  # Replace with your preferred mode: WALK, BIKE, CAR, TRANSIT
  max_trip_duration = 600  # Maximum trip duration in minutes
)

# View the travel time matrix
head(ttm)
```

##按书上的来
```{r}
data_path <- system.file("extdata/poa", package = "r5r") 
data_path
```
```{r}
fs::dir_tree(data_path)
```
```{r}
options(java.parameters = "-Xmx2G")
```

```{r}
r5r_core <- setup_r5(data_path, verbose = FALSE) 
fs::dir_tree(data_path)
```
```{r}
# Check if r5r_core is not NULL
if (!is.null(r5r_core)) {
  print("R5 transport network setup successfully.")
} else {
  stop("Failed to setup R5 transport network.")
}
```

```{r}
# read data.frame with grid centroids 
points1 <- data.table::fread(file.path(data_path, "poa_hexgrid.csv"))

ttm <- travel_time_matrix(
  r5r_core, 
  origins = points1, 
  destinations = points1, 
  mode = c("TRANSIT"), 
  max_trip_duration = 120, 
  verbose = FALSE, 
  progress = FALSE 
) 
head(ttm)
```






# DRAFT for seperation - FAIL
## With Classification
```{r eval=FALSE}
# Classify rows based on SIC_Codes (if you have specific classifications)
# Here, I'm assuming you want to perform clustering directly on rows with different SIC_Codes
nested_points <- points %>% 
  group_by(SIC_Section) %>% 
  nest()
```
determine eps and minPts
```{r eval=FALSE}
# Example: Use the Manufacturing sector to determine eps
first_group <- nested_points$data[[which(nested_points$SIC_Sector == "Manufacturing")]]

# Extract coordinates and convert to data frame
coords <- st_coordinates(first_group)
df <- as.data.frame(coords)

# Plot k-nearest neighbors distance to find the knee
dbscan::kNNdistplot(df, k = 4)
abline(h = 200, col = "red", lty = 2)  # Adjust based on the knee point
```
Clustering
```{r eval=FALSE}
# Determine the optimal eps value using the kNNdistplot
perform_clustering <- function(df) {
  # Select numeric columns for clustering
  numeric_data <- df %>%
    st_coordinates() %>% 
    as.data.frame()
  
  # Standardize the numeric data
  numeric_data_scaled <- scale(numeric_data)
  
  # Perform K-means clustering (example with 3 clusters)
  set.seed(123)
  kmeans_result <- kmeans(numeric_data_scaled, centers = 3, nstart = 25)
  
  # Add the cluster assignment to the original data
  df$cluster <- kmeans_result$cluster
  
  return(df)
}

# Apply the clustering function to each nested group
nested_points <- nested_points %>%
  mutate(data = map(data, perform_clustering))
```
Vistualization
```{r eval=FALSE}
# Combine the clustered data back into a single data frame
clustered_points <- nested_points %>%
  unnest(cols = c(data))

# Plot the clusters using ggplot2
plot_clusters <- function(df, group_name) {
  ggplot(df, aes(x = X, y = Y, color = as.factor(cluster))) +
    geom_point() +
    labs(title = paste("Clusters for", group_name), color = "Cluster") +
    theme_minimal() +
    coord_equal()
}

# Apply the plot function to each group
plots <- nested_points %>%
  mutate(plot = map2(data, SIC_Sector, plot_clusters))

# Display the plots
for (p in plots$plot) {
  print(p)
}
```

